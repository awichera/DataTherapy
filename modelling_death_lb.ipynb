{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e8ff5f8-ecd9-46dc-bf9e-ef83b87324f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import mlflow\n",
    "from pyspark.sql import functions as f\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, precision_recall_curve, average_precision_score\n",
    "import seaborn as sns\n",
    "from pyspark.sql.types import IntegerType\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c5516d8-74f4-4491-bd93-5d8ac919afd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "feature_cols_post_care = [\n",
    "#\"id\",\n",
    " #### diagnoza ####\n",
    " 'diagnoza_detail_kod', # cat IMPORTANT!\n",
    " # 'diagnoza_kod', # vzdy c50, nema smysl\n",
    " 'lateralita_kod', # num\n",
    " 'topografie_kod', # cat zahodit?\n",
    " 'morfologie_kod', # cat zahodit?\n",
    " 'grading', # numerizujeme ###\n",
    " 'tnm_klasifikace_t_kod', # numerizujeme\n",
    " 'tnm_klasifikace_n_kod', # numerizujeme\n",
    " 'tnm_klasifikace_m_kod', # numerizujeme\n",
    " 'tnm_klasifikace_metastazy_oth', # bool\n",
    " 'tnm_klasifikace_metastazy_ski', # bool\n",
    " 'tnm_klasifikace_metastazy_lym', # bool\n",
    " 'tnm_klasifikace_metastazy_adr', # bool\n",
    " 'tnm_klasifikace_metastazy_bra', # bool\n",
    " 'tnm_klasifikace_metastazy_per', # bool\n",
    " 'tnm_klasifikace_metastazy_hep', # bool\n",
    " 'tnm_klasifikace_metastazy_ple', # bool\n",
    " 'tnm_klasifikace_metastazy_oss', # bool\n",
    " 'tnm_klasifikace_metastazy_mar', # bool\n",
    " 'tnm_klasifikace_metastazy_pul', # bool\n",
    " 'tnm_klasifikace_metastazy_xxx', # bool\n",
    " # 'tnm_klasifikace_vysledna', zahazujeme duplikace \n",
    " 'stadium', # numerizujeme\n",
    " # 'rok_dg',\n",
    " # 'mesic_dg',\n",
    " \n",
    " #### pacient ####\n",
    " 'vekova_kategorie_10let_dg', # numerizujeme\n",
    " 'novotvar_poradi', # num\n",
    " 'novotvar_poradi_dg', # bool\n",
    " 'novotvar_poradi_dg_skupina', # bool\n",
    " 'novotvar_poradi_dg_maligni', # num\n",
    " 'novotvar_poradi_dg_maligni_bez_c44',\n",
    " \n",
    " #### pridruzene diagnozy ####\n",
    " 'DCCI', # num\n",
    " 'dcci_infarkt_myokardu', # bool\n",
    " 'dcci_srdecni_selhani', # bool\n",
    " 'dcci_onemocneni_perifernich_cev', # bool\n",
    " 'dcci_cevni_nemoci_mozku', # bool\n",
    " 'dcci_demence', # bool\n",
    " 'dcci_chronicke_plicni_onemocneni', # bool\n",
    " 'dcci_onemocneni_pojivovych_tkani', # bool\n",
    " 'dcci_vredova_onemocneni', # bool\n",
    " 'dcci_mirna_onemocneni_jater', # bool\n",
    " 'dcci_diabetes_bez_chronickych_komplikaci', # bool\n",
    " 'dcci_diabetes_s_chronickymi_komplikacemi', # bool\n",
    " 'dcci_hemiplegia_or_paraplegia', # bool\n",
    " 'dcci_onemocneni_ledvin', # bool\n",
    " 'dcci_nadorova_onemocneni', # bool\n",
    " 'dcci_stredne_zavazne_nebo_vazne_onemocneni_jater', # bool\n",
    " 'dcci_nadorova_onemocneni_s_metastazemi', # bool\n",
    " 'time_indexdate_to_datum_dg', # num\n",
    " \n",
    " #### vysetreni pri primarni diagnoze ####\n",
    " 'pd_ct', # bool\n",
    " 'pd_petct', # bool\n",
    " 'pd_mr', # bool\n",
    " 'pd_scint', # bool\n",
    " 'pd_spect', # bool\n",
    " 'pd_rtg', # bool\n",
    " 'pd_sono', # bool\n",
    " 'pd_mamo', # bool\n",
    " 'pd_screening', # bool\n",
    " 'pd_jina', # bool\n",
    "\n",
    " #### Provedeni konsilia ####\n",
    " 'je_mdt',\n",
    " 'time_indexdate_to_mdt',\n",
    " \n",
    " ### # Kde je pacient lecen ####\n",
    " # 'je_pl', # zahodit, nelecene vyhodime z datasetu\n",
    " 'je_pl_koc',\n",
    " 'je_pl_roc',\n",
    " 'je_pl_jinde',\n",
    "\n",
    " #### Delka a zpozdeni zahajeni prim lecby ####\n",
    " 'time_datum_dg_to_zahajeni_pl',\n",
    " 'pl_delka',\n",
    " \n",
    " #### Uzite modality lecby #### \n",
    " 'je_pl_oper',\n",
    " 'je_pl_radio',\n",
    " 'je_pl_target',\n",
    " 'je_pl_chemo',\n",
    " 'je_pl_hormo',\n",
    " 'je_pl_imuno',\n",
    " 'pl_pocet_leceb',\n",
    "\n",
    "#### Poradi modalit lecby #### \n",
    "#  'pl_typ_lecby_1',\n",
    "#  'pl_kod_lecby_1',\n",
    "#  'pl_typ_lecby_2',\n",
    "#  'pl_kod_lecby_2',\n",
    "#  'pl_typ_lecby_3',\n",
    "#  'pl_kod_lecby_3',\n",
    "#  'pl_typ_lecby_4',\n",
    "#  'pl_kod_lecby_4',\n",
    "#  'pl_typ_lecby_5',\n",
    "#  'pl_kod_lecby_5',\n",
    "#  'pl_typ_lecby_6',\n",
    "#  'pl_kod_lecby_6',\n",
    "#  'pl_typ_lecby_7',\n",
    "#  'pl_kod_lecby_7',\n",
    "#  'pl_typ_lecby_8',\n",
    "#  'pl_kod_lecby_8',\n",
    "#  'pl_typ_lecby_9',\n",
    "#  'pl_kod_lecby_9',\n",
    "#  'pl_typ_lecby_10',\n",
    "#  'pl_kod_lecby_10',\n",
    " \n",
    " #### Hospitalizace #### \n",
    " 'pl_pocet_hp',\n",
    " 'pl_hp_los',\n",
    " 'pl_hp_od_stan',\n",
    " 'pl_hp_od_int',\n",
    " 'pl_hp_drg_prvni',\n",
    " 'pl_hp_drg_posledni',\n",
    "\n",
    " #### Vysetreni pri / po konci pl ####\n",
    " 'pl_ct',\n",
    " 'pl_petct',\n",
    " 'pl_mr',\n",
    " 'pl_scint',\n",
    " 'pl_spect',\n",
    " 'pl_rtg',\n",
    " 'pl_sono',\n",
    " 'pl_mamo',\n",
    " 'pl_jina',\n",
    "\n",
    " #### Disperzni vysetreni ####\n",
    " # nedavat, po skonceni pl\n",
    "#  'je_disp',\n",
    "#  'je_disp_prakt',\n",
    "#  'je_disp_onk',\n",
    "#  'je_disp_int',\n",
    "#  'je_disp_chir',\n",
    "#  'je_disp_gyn',\n",
    "\n",
    "#### Navstevy a body #### #nemuzem az do nl\n",
    " # 'amb_onk_navstevy', \n",
    "#  'amb_onk_body_rok1',\n",
    "#  'amb_onk_body_rok2',\n",
    "#  'amb_onk_body_rok3',\n",
    "#  'amb_onk_body_rok4',\n",
    "#  'amb_onk_body_rok5',\n",
    "#  'amb_int_navstevy',\n",
    "#  'amb_int_body_rok1',\n",
    "#  'amb_int_body_rok2',\n",
    "#  'amb_int_body_rok3',\n",
    "#  'amb_int_body_rok4',\n",
    "#  'amb_int_body_rok5',\n",
    "#  'amb_chir_navstevy',\n",
    "#  'amb_chir_body_rok1',\n",
    "#  'amb_chir_body_rok2',\n",
    "#  'amb_chir_body_rok3',\n",
    "#  'amb_chir_body_rok4',\n",
    "#  'amb_chir_body_rok5',\n",
    "#  'amb_gyn_navstevy',\n",
    "#  'amb_gyn_body_rok1',\n",
    "#  'amb_gyn_body_rok2',\n",
    "#  'amb_gyn_body_rok3',\n",
    "#  'amb_gyn_body_rok4',\n",
    "#  'amb_gyn_body_rok5',\n",
    "#  'amb_celkem_navstevy',\n",
    "#  'amb_celkem_body_rok1',\n",
    "#  'amb_celkem_body_rok2',\n",
    "#  'amb_celkem_body_rok3',\n",
    "#  'amb_celkem_body_rok4',\n",
    "#  'amb_celkem_body_rok5',\n",
    " \n",
    " #### Naslenda lecba ####\n",
    "#  'je_nl',\n",
    "#  'je_nl_koc',\n",
    "#  'je_nl_roc',\n",
    "#  'je_nl_jinde',\n",
    "#  'time_datum_dg_to_zahajeni_nl',\n",
    "#  'nl_delka',\n",
    "#  'je_nl_oper',\n",
    "#  'je_nl_radio',\n",
    "#  'je_nl_target',\n",
    "#  'je_nl_chemo',\n",
    "#  'je_nl_hormo',\n",
    "#  'je_nl_imuno',\n",
    "#  'nl_pocet_leceb',\n",
    "#  'nl_typ_lecby_1',\n",
    "#  'nl_kod_lecby_1',\n",
    "#  'nl_typ_lecby_2',\n",
    "#  'nl_kod_lecby_2',\n",
    "#  'nl_typ_lecby_3',\n",
    "#  'nl_kod_lecby_3',\n",
    "#  'nl_typ_lecby_4',\n",
    "#  'nl_kod_lecby_4',\n",
    "#  'nl_typ_lecby_5',\n",
    "#  'nl_kod_lecby_5',\n",
    "#  'nl_typ_lecby_6',\n",
    "#  'nl_kod_lecby_6',\n",
    "#  'nl_typ_lecby_7',\n",
    "#  'nl_kod_lecby_7',\n",
    "#  'nl_typ_lecby_8',\n",
    "#  'nl_kod_lecby_8',\n",
    "#  'nl_typ_lecby_9',\n",
    "#  'nl_kod_lecby_9',\n",
    "#  'nl_typ_lecby_10',\n",
    "#  'nl_kod_lecby_10',\n",
    "#  'nl_pocet_hp',\n",
    "#  'nl_hp_los',\n",
    "#  'nl_hp_od_stan',\n",
    "#  'nl_hp_od_int',\n",
    "#  'nl_hp_drg_prvni',\n",
    "#  'nl_hp_drg_posledni',\n",
    "\n",
    "#### Souhrn a smrti ####\n",
    "#  'souhrn_diagnoz',\n",
    "#  'nl_only_hormo',\n",
    "#  'nl_others',\n",
    "\"dead_5_years_bc\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "465f48de-1909-442c-a6ab-7f6236885423",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"I2RmID0gKHNwYXJrLnJlYWQudGFibGUoInJha2F0aG9uX2hhY2thdGhvbi5yZWt1cnplLnJla3VyemVfZGVhdGhfaW5pdGlhbF9zZXRfY2Vuc3VyZWQiKQpkZiA9IChzcGFyay5yZWFkLnRhYmxlKCJyYWthdGhvbl9oYWNrYXRob24ucmVrdXJ6ZS5yZWt1cnplX2RlYXRoX2luaXRpYWxfc2V0X2NlbnN1cmVkX29wcmF2YSIpCiAgICAgIC53aXRoQ29sdW1uKCJzdGFkaXVtIiwgZi53aGVuKGYuY29sKCJzdGFkaXVtIikuaXNpbigiMSIsICIyIiwgIjMiLCAiNCIpLCBmLmNvbCgic3RhZGl1bSIpKS5vdGhlcndpc2UoTm9uZSkpCiAgICAgIC53aXRoQ29sdW1uKCJzdGFkaXVtIiwgZi5jb2woInN0YWRpdW0iKS5jYXN0KEludGVnZXJUeXBlKCkpKQogICAgICAuc2VsZWN0KCpmZWF0dXJlX2NvbHNfcG9zdF9jYXJlKQogICAgICAuZmlsdGVyKGYuY29sKCJqZV9wbCIpPT0xKQogICAgICAuZmlsdGVyKGYuY29sKCJkZWFkXzVfeWVhcnNfYmMiKS5pc05vdE51bGwoKSkpCgojZGlzcGxheShkZi5maWx0ZXIoZi5jb2woImplX3BsIik9PTEpLmNvdW50KCkpCiNkaXNwbGF5KGRmLmZpbHRlcihmLmNvbCgicGxfZGVsa2EiKS5pc05vdE51bGwoKSkuY291bnQoKSkKI2Rpc3BsYXkoZGYuY291bnQoKSkKZGlzcGxheShkZik=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView4efaaad\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView4efaaad\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView4efaaad\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView4efaaad) SELECT `dead_5_years_bc`,COUNT(*) `column_42978ea550`,`dead_5_years_bc` FROM q GROUP BY `dead_5_years_bc`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView4efaaad\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "series": {
             "column": "dead_5_years_bc",
             "id": "column_42978ea548"
            },
            "x": {
             "column": "dead_5_years_bc",
             "id": "column_42978ea547"
            },
            "y": [
             {
              "column": "*",
              "id": "column_42978ea550",
              "transform": "COUNT"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_42978ea550": {
             "type": "column",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 1744500999873,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": [
        [
         "table",
         2
        ]
       ],
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "2059091d-7025-4a55-8cb7-b9889ec38fd0",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 2.5,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 1744500998725,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "dead_5_years_bc",
           "type": "column"
          },
          {
           "column": "dead_5_years_bc",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "dead_5_years_bc",
           "type": "column"
          },
          {
           "alias": "column_42978ea550",
           "args": [
            {
             "column": "*",
             "type": "column"
            }
           ],
           "function": "COUNT",
           "type": "function"
          },
          {
           "column": "dead_5_years_bc",
           "type": "column"
          }
         ]
        }
       },
       "submitTime": 1744500982668,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df = (spark.read.table(\"rakathon_hackathon.rekurze.rekurze_death_initial_set_censured\")\n",
    "df = (spark.read.table(\"rakathon_hackathon.rekurze.rekurze_death_initial_set_censured_oprava\")\n",
    "      .withColumn(\"stadium\", f.when(f.col(\"stadium\").isin(\"1\", \"2\", \"3\", \"4\"), f.col(\"stadium\")).otherwise(None))\n",
    "      .withColumn(\"stadium\", f.col(\"stadium\").cast(IntegerType()))\n",
    "      .select(*feature_cols_post_care)\n",
    "      .filter(f.col(\"je_pl\")==1)\n",
    "      .filter(f.col(\"dead_5_years_bc\").isNotNull()))\n",
    "\n",
    "#display(df.filter(f.col(\"je_pl\")==1).count())\n",
    "#display(df.filter(f.col(\"pl_delka\").isNotNull()).count())\n",
    "#display(df.count())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d690f7a-1e19-41d5-8d7f-cbcb2040b7b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Convert Spark DF to pandas\n",
    "df_pd = df.toPandas()\n",
    "\n",
    "# 2. Define X, y\n",
    "target_col = \"dead_5_years_bc\"\n",
    "X = df_pd.drop(columns=[target_col])\n",
    "y = df_pd[target_col]\n",
    "\n",
    "# 3. Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
    "\n",
    "# 4. Define preprocessor (OneHotEncoder only for categorical)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        #(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "        (\"num\", \"passthrough\", numerical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5. Define pipeline with preprocessor + model\n",
    "model_params = {\n",
    "    \"use_label_encoder\":True,\n",
    "    \"eval_metric\":\"auc\",\n",
    "    \"n_estimators\":1000,\n",
    "    \"max_depth\":15,\n",
    "    \"learning_rate\":0.01,\n",
    "    \"subsample\":0.8\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", XGBClassifier(\n",
    "        **model_params\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 6. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 7. MLflow tracking\n",
    "with mlflow.start_run(run_name=\"rackathon_xgboost_pipeline\"):\n",
    "    # Log parameters manually\n",
    "    mlflow.log_params(model_params)\n",
    "\n",
    "    # Fit pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metrics({\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": f1,\n",
    "        \"recall\": recall,\n",
    "        \"precision\":precision,\n",
    "    })\n",
    "\n",
    "    # Log pipeline model (includes preprocessing)\n",
    "    mlflow.sklearn.log_model(pipeline, artifact_path=\"xgb_pipeline_model\")\n",
    "\n",
    "    print(f\"‚úÖ Accuracy: {accuracy:.4f} | F1: {f1:.4f} | Recall: {recall:.4f} | Precision: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b78631a-acf1-4966-ab63-9b8dee80f0bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_pred_proba_b = [x[1] for x in y_pred_proba]\n",
    "df_test = pd.DataFrame({\"y_test_gt\":y_test, \"y_test_pred_proba\":y_pred_proba_b})\n",
    "\n",
    "sns.displot(\n",
    "    data=df_test,\n",
    "    x=\"y_test_pred_proba\",\n",
    "    hue=\"y_test_gt\",\n",
    "    #kind=\"kde\",\n",
    "    common_norm=False,\n",
    "    stat=\"density\",\n",
    "    height=7,\n",
    "    aspect=2\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba18110a-4e18-4f51-bf1b-5e7d5974de35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pipeline.steps[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae2d3d2b-2508-468e-8583-9c7534f73ab8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a37b845a-11ea-445f-abe1-9526f1101bf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3250c736-ea81-4750-a5d8-4086ddb4db38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Predict probabilities for class 1\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute precision-recall pairs and AUPRC\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "auprc = average_precision_score(y_test, y_proba)\n",
    "\n",
    "# Plot PR curve\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(recall, precision, label=f\"AUPRC = {auprc:.4f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92f47ad1-9acb-4375-aab2-e15c5ee090ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73824889-3a3b-4a36-83ef-c4339f89a1fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train[\"target\"] = y_train\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c5ce836-a970-48c3-a364-a9c6a0613df4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca7ff7d4-d208-4b1c-a1ff-5ab7035c7fc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## shapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98ae02be-ad86-47cb-ace8-90f494a78759",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Extract model and preprocessor from pipeline\n",
    "model = pipeline.named_steps[\"classifier\"]\n",
    "preprocessor = pipeline.named_steps[\"preprocessor\"]\n",
    "\n",
    "# 2. Transform X_test using the fitted preprocessor\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# 3. Get feature names from preprocessor\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# 4. Convert transformed data to DataFrame with correct feature names\n",
    "X_test_transformed_df = pd.DataFrame(\n",
    "    X_test_transformed.toarray() if hasattr(X_test_transformed, \"toarray\") else X_test_transformed,\n",
    "    columns=feature_names\n",
    ")\n",
    "\n",
    "# 5. Create SHAP explainer for the XGBoost model\n",
    "explainer = shap.Explainer(model)\n",
    "\n",
    "# 6. Compute SHAP values\n",
    "shap_values = explainer(X_test_transformed_df)\n",
    "\n",
    "# 7. Plot SHAP summary with feature names\n",
    "shap.initjs()\n",
    "shap.summary_plot(shap_values, X_test_transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a05c5fd8-dfa4-40aa-b733-1fb279db1af0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Index of the highest probability\n",
    "max_index = np.argmax(y_proba)\n",
    "min_index = np.argmin(y_proba)\n",
    "\n",
    "# Value at that index\n",
    "max_proba = y_proba[max_index]\n",
    "min_proba = y_proba[min_index]\n",
    "\n",
    "print(f\"üî• Highest predicted probability is {max_proba:.4f} at index {max_index}\")\n",
    "print(f\"üî• Highest predicted probability is {min_proba:.4f} at index {min_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c30046a6-6364-48df-911b-a9305cbcccfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: get preprocessed test data\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Step 2: convert to DataFrame for explainability\n",
    "X_test_transformed_df = pd.DataFrame(\n",
    "    X_test_transformed.toarray() if hasattr(X_test_transformed, \"toarray\") else X_test_transformed,\n",
    "    columns=feature_names\n",
    ")\n",
    "\n",
    "def explain_prediction(i, model, explainer, shap_values, X_test_transformed_df, original_X_test):\n",
    "    print(f\"\\nüîç Explanation for Row #{i}\")\n",
    "    proba = pipeline.predict_proba(original_X_test.iloc[[i]])[0, 1]\n",
    "    print(f\"üîÆ Predicted Probability of relaps in 5 years: {proba:.4f}\\n\")\n",
    "    \n",
    "    shap.initjs()\n",
    "    return shap.force_plot(\n",
    "        explainer.expected_value,\n",
    "        shap_values[i].values,\n",
    "        X_test_transformed_df.iloc[i],\n",
    "        matplotlib=True\n",
    "    )\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "explain_prediction(14, model, explainer, shap_values, X_test_transformed_df, X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52481efd-90bd-443f-a6f1-e7591810ead7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# inference df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1a4b7b4-8bea-42c5-8b2c-bd48ca2704fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Read the original row by ID\n",
    "original_df = (\n",
    "    spark.read.table(\"rakathon_hackathon.rekurze.rekurze_death_initial_set_censured\")\n",
    "    .filter(f.col(\"id\") == 213730)\n",
    ")\n",
    "\n",
    "# 2. Modify the stadium column from 1 to 3\n",
    "modified_df = original_df.withColumn(\"je_pl_radio\", f.lit(0)) # je_pl_koc\n",
    "\n",
    "# 3. Union original + modified row (optional)\n",
    "inference_df = original_df.unionByName(modified_df).select(*feature_cols_post_care)\n",
    "\n",
    "# 4. Show both rows (for verification)\n",
    "display(inference_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "075653d7-81ab-40b5-9690-133423affe2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's assume your modified Spark DataFrame is called `result_df`\n",
    "pandas_input = inference_df.toPandas()\n",
    "X_new = pandas_input.drop(columns=[target_col,\"id\"], errors=\"ignore\")  # or add 'relaps_5_years' if it's present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c32f7c1-38d0-4a61-9f9d-0536dcdb630f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Predict class\n",
    "pred_class = pipeline.predict(X_new)\n",
    "\n",
    "# Predict probability (positive class, e.g. relaps in 5 years)\n",
    "pred_proba = pipeline.predict_proba(X_new)[:, 1]\n",
    "\n",
    "\n",
    "display(pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb0d1bb7-5378-4f8f-8020-ecfc63bf2e89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: get preprocessed test data\n",
    "X_test_transformed = preprocessor.transform(X_new)\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Step 2: convert to DataFrame for explainability\n",
    "X_test_transformed_df = pd.DataFrame(\n",
    "    X_test_transformed.toarray() if hasattr(X_test_transformed, \"toarray\") else X_test_transformed,\n",
    "    columns=feature_names\n",
    ")\n",
    "\n",
    "def explain_prediction(i, model, explainer, shap_values, X_test_transformed_df, original_X_test):\n",
    "    print(f\"\\nüîç Explanation for Row #{i}\")\n",
    "    proba = pipeline.predict_proba(original_X_test.iloc[[i]])[0, 1]\n",
    "    print(f\"üîÆ Predicted Probability of relaps in 5 years: {proba:.4f}\\n\")\n",
    "    \n",
    "    shap.initjs()\n",
    "    return shap.force_plot(\n",
    "        explainer.expected_value,\n",
    "        shap_values[i].values,\n",
    "        X_test_transformed_df.iloc[i],\n",
    "        matplotlib=True\n",
    "    )\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "explain_prediction(0, model, explainer, shap_values, X_test_transformed_df, X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "714fd236-3aae-4953-a5db-96b88355bc8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "explain_prediction(1, model, explainer, shap_values, X_test_transformed_df, X_new) # Tomuhle p≈ôidat hormono"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b644776e-9649-4453-80ac-6e9781b0b765",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4d6d7a5-841d-40a6-9205-7b4660d5149b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "# 1. Get predicted probabilities for positive class (relaps=1)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 2. Compute calibration curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_proba, n_bins=10, strategy=\"quantile\")\n",
    "\n",
    "# 3. Plot calibration curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(prob_pred, prob_true, marker='o', label=\"XGBoost Pipeline\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label=\"Perfect Calibration\")\n",
    "plt.xlabel(\"Mean Predicted Probability\")\n",
    "plt.ylabel(\"True Fraction of Positives\")\n",
    "plt.title(\"Calibration Curve (Reliability Diagram)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Optional: plot histogram of predicted probabilities\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.hist(y_proba, bins=20, edgecolor='k')\n",
    "plt.title(\"Histogram of Predicted Probabilities\")\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "modelling_death_lb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
